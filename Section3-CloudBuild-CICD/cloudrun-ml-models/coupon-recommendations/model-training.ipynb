{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator type: UNDEFINED\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "`_estimator_type` undefined.  Please use appropriate mixin to define estimator type.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 118\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# 6. Train and Save\u001b[39;00m\n\u001b[32m    117\u001b[39m model = train_model(\u001b[33m'\u001b[39m\u001b[33mxgboost\u001b[39m\u001b[33m'\u001b[39m, x_sm_train, y_sm_train)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43martifacts/xgboost_coupon_recommendation.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# 7. Quick Evaluation\u001b[39;00m\n\u001b[32m    121\u001b[39m preds = model.predict(x_test_hashing)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36msave_model\u001b[39m\u001b[34m(model, file_path)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Save as JSON for better portability/security as discussed\u001b[39;00m\n\u001b[32m     83\u001b[39m json_path = file_path.replace(\u001b[33m\"\u001b[39m\u001b[33m.pkl\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Model successfully saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/coupon-ml/lib/python3.11/site-packages/xgboost/sklearn.py:820\u001b[39m, in \u001b[36mXGBModel.save_model\u001b[39m\u001b[34m(self, fname)\u001b[39m\n\u001b[32m    818\u001b[39m meta: Dict[\u001b[38;5;28mstr\u001b[39m, Any] = {}\n\u001b[32m    819\u001b[39m \u001b[38;5;66;03m# For validation.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m meta[\u001b[33m\"\u001b[39m\u001b[33m_estimator_type\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    821\u001b[39m meta_str = json.dumps(meta)\n\u001b[32m    822\u001b[39m \u001b[38;5;28mself\u001b[39m.get_booster().set_attr(scikit_learn=meta_str)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/coupon-ml/lib/python3.11/site-packages/xgboost/sklearn.py:811\u001b[39m, in \u001b[36mXGBModel._get_type\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    809\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_type\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    810\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_estimator_type\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    812\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`_estimator_type` undefined.  \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    813\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPlease use appropriate mixin to define estimator type.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    814\u001b[39m         )\n\u001b[32m    815\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._estimator_type\n",
      "\u001b[31mTypeError\u001b[39m: `_estimator_type` undefined.  Please use appropriate mixin to define estimator type."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders import HashingEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def load_data(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Data file not found at {file_path}\")\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # 1. Basic Cleaning\n",
    "    df = df.drop(columns=['car', 'toCoupon_GEQ5min', 'direction_opp'])\n",
    "    df = df.fillna(df.mode().iloc[0])\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # 2. Manual Encoding (Ensures ordinal relationships are preserved)\n",
    "    encoding_map = {\n",
    "        'expiration': {'2h': 0, '1d': 1},\n",
    "        'age': {'<21': 0, '21-30': 1, '31-40': 2, '41-50': 3, '>50': 4},\n",
    "        'education': {\n",
    "            'Some High School': 0, 'High School Graduate': 1, 'Some college - no degree': 2,\n",
    "            'Associates degree': 3, 'Bachelors degree': 4, 'Graduate degree (Masters or Doctorate)': 5\n",
    "        },\n",
    "        'Bar': {'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4},\n",
    "        'CoffeeHouse': {'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4}, \n",
    "        'CarryAway': {'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4}, \n",
    "        'Restaurant20To50': {'never': 0, 'less1': 1, '1~3': 2, '4~8': 3, 'gt8': 4},\n",
    "        'income': {\n",
    "            'Less than $12500': 0, '$12500 - $24999': 1, '$25000 - $37499': 2, '$37500 - $49999': 3,\n",
    "            '$50000 - $62499': 4, '$62500 - $74999': 5, '$75000 - $87499': 6, '$87500 - $99999': 7,\n",
    "            '$100000 or More': 8\n",
    "        },\n",
    "        'time': {'7AM': 0, '10AM': 1, '2PM': 2, '6PM': 3, '10PM': 4}\n",
    "    }\n",
    "\n",
    "    for col, mapping in encoding_map.items():\n",
    "        if col in df.columns:\n",
    "            # .map is more direct than .replace for this use case\n",
    "            df[col] = df[col].map(mapping).fillna(-1).astype(int)\n",
    "\n",
    "    # 3. Engineered Features\n",
    "    df['passanger_destination'] = df['passanger'].astype(str) + '-' + df['destination'].astype(str)\n",
    "    df['marital_hasChildren'] = df['maritalStatus'].astype(str) + '-' + df['has_children'].astype(str)\n",
    "    df['temperature_weather'] = df['temperature'].astype(str) + '-' + df['weather'].astype(str)\n",
    "    \n",
    "    # Drop original categorical components\n",
    "    df = df.drop(columns=['passanger', 'destination', 'maritalStatus', 'has_children', \n",
    "                          'temperature', 'weather', 'gender', 'RestaurantLessThan20'])\n",
    "    \n",
    "    x = df.drop('Y', axis=1)\n",
    "    y = df.Y\n",
    "    return x, y\n",
    "\n",
    "def train_model(model_name, x_train, y_train):\n",
    "    if model_name == 'xgboost':\n",
    "        # Explicitly use the Classifier class\n",
    "        model = XGBClassifier(\n",
    "            random_state=42, \n",
    "            learning_rate=0.2, \n",
    "            n_estimators=45, \n",
    "            max_depth=10,\n",
    "            use_label_encoder=False  # Good practice for older versions\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name.\")\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # Debug check: Ensure the model knows it's a classifier\n",
    "    print(f\"Estimator type: {getattr(model, '_estimator_type', 'UNDEFINED')}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def save_model(model, file_path):\n",
    "    # Ensure we use the .json extension\n",
    "    json_path = file_path.replace(\".pkl\", \".json\")\n",
    "    \n",
    "    # Access the underlying booster to bypass the scikit-learn wrapper bug\n",
    "    # This is the \"pure\" XGBoost model engine\n",
    "    model.get_booster().save_model(json_path)\n",
    "    \n",
    "    print(f\"✅ Model successfully saved to {json_path}\")\n",
    "\n",
    "# --- EXECUTION FLOW ---\n",
    "\n",
    "# 1. Load and Preprocess\n",
    "df = load_data(\"data/in-vehicle-coupon-recommendation.csv\")\n",
    "x, y = preprocess_data(df)\n",
    "\n",
    "# 2. Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 3. Handle Remaining Categoricals via Hashing\n",
    "# These are columns we didn't manually encode above\n",
    "hash_cols = ['passanger_destination', 'marital_hasChildren', 'occupation', 'coupon', 'temperature_weather']\n",
    "hashing_enc = HashingEncoder(cols=hash_cols, n_components=27).fit(x_train)\n",
    "\n",
    "x_train_hashing = hashing_enc.transform(x_train.reset_index(drop=True))\n",
    "x_test_hashing = hashing_enc.transform(x_test.reset_index(drop=True))\n",
    "\n",
    "# 4. Final Type Check (Crucial for XGBoost)\n",
    "non_numeric_cols = x_train_hashing.select_dtypes(exclude=['number']).columns.tolist()\n",
    "if non_numeric_cols:\n",
    "    print(f\"⚠️ Warning: Still have non-numeric columns: {non_numeric_cols}\")\n",
    "    # Force conversion of any straggler objects to numeric\n",
    "    for col in non_numeric_cols:\n",
    "        x_train_hashing[col] = pd.to_numeric(x_train_hashing[col], errors='coerce').fillna(0)\n",
    "\n",
    "# 5. Over-sampling with SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "x_sm_train, y_sm_train = sm.fit_resample(x_train_hashing, y_train)\n",
    "\n",
    "# 6. Train and Save\n",
    "model = train_model('xgboost', x_sm_train, y_sm_train)\n",
    "save_model(model, \"artifacts/xgboost_coupon_recommendation.json\")\n",
    "\n",
    "# 7. Quick Evaluation\n",
    "preds = model.predict(x_test_hashing)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, preds):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 show xgboost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coupon-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
